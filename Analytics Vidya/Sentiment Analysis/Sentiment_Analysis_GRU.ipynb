{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis - LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhBFzje-t_XX"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELcBE6BiuBL0",
        "outputId": "3d8d74f7-fe65-4c98-dea8-a774ca12c2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgXUEJwuDwW"
      },
      "source": [
        "sample_text_1=\"bitty bought a bit of butter\"\n",
        "sample_text_2=\"but the bit of butter was a bit bitter\"\n",
        "sample_text_3=\"so she bought some better butter to make the bitter butter better\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgEQAE49vtMm",
        "outputId": "c0aa3772-9e9d-4d3c-bcb6-abd9b9ca7350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdMw5rZkv363"
      },
      "source": [
        "from nltk import word_tokenize"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcmULSaNuLJR"
      },
      "source": [
        "corpus = [sample_text_1, sample_text_2, sample_text_3]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcQyFm9mv9Tz",
        "outputId": "a70feefa-2c6d-4cdb-9fa6-4d970b882c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bitty bought a bit of butter',\n",
              " 'but the bit of butter was a bit bitter',\n",
              " 'so she bought some better butter to make the bitter butter better']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RrpUUR-v--E"
      },
      "source": [
        "corpus = [word_tokenize(x) for x in corpus]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzI8EnAewM-J",
        "outputId": "e22972cc-9d0d-4428-c254-3efe8ce2a7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['bitty', 'bought', 'a', 'bit', 'of', 'butter'],\n",
              " ['but', 'the', 'bit', 'of', 'butter', 'was', 'a', 'bit', 'bitter'],\n",
              " ['so',\n",
              "  'she',\n",
              "  'bought',\n",
              "  'some',\n",
              "  'better',\n",
              "  'butter',\n",
              "  'to',\n",
              "  'make',\n",
              "  'the',\n",
              "  'bitter',\n",
              "  'butter',\n",
              "  'better']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWyPdVFiwR_s"
      },
      "source": [
        "from nltk.corpus import  stopwords"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3jJRAzjwdTB"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVUrxzfwdXX",
        "outputId": "dc1cb579-ae50-402c-822d-c8237aaa41e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(stop_words)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'which', 'above', 'we', \"she's\", 'who', 'into', 'further', 'hadn', 'now', 'needn', 'doesn', 'mightn', 'if', 'against', 'has', 'or', \"mightn't\", 'about', 'most', 'ourselves', 'all', 'y', 'too', 'own', 'with', 'there', \"shouldn't\", 'out', \"won't\", 'ain', \"you've\", 'had', 'don', 've', 'do', 'being', 'didn', 'ma', 'whom', 'have', 'the', \"you're\", 'his', \"didn't\", 'its', 'such', 'o', 'what', 'is', 'won', \"don't\", 'nor', 'once', 'more', 'between', 'was', 'until', 'myself', 'wasn', \"should've\", 'then', \"haven't\", 'her', 'ours', 'up', 'your', 'our', 'why', 'itself', 'yourself', 'it', 'those', 'should', 'of', 't', 'off', 'aren', 'to', 'and', 'as', 'themselves', \"you'll\", 'does', 'him', 'on', 'my', 'can', 'just', 'very', 'theirs', \"that'll\", 'yourselves', 'during', 'how', 'i', 'am', 'some', 'than', \"hadn't\", 'down', 're', \"it's\", 'other', 'at', 'these', 'while', 'this', 'having', 'they', 'no', 'himself', 'both', \"mustn't\", 'here', 'where', 'so', 'couldn', 'been', 'an', 'be', 'did', 'were', 'any', 'under', 'for', \"wasn't\", 'same', 'isn', 'few', 'from', 'by', 'below', 'hasn', \"hasn't\", 'a', 'yours', \"aren't\", 'their', 'through', 'each', 'haven', \"you'd\", \"couldn't\", 'but', 'because', 'hers', \"isn't\", 'm', \"weren't\", 'you', \"needn't\", 'again', 'them', 'he', 'mustn', 'weren', 'wouldn', 'd', 'after', 'shan', 'doing', 'before', 'she', 'in', \"doesn't\", 'when', 'herself', 'are', 'over', 'll', \"wouldn't\", 's', 'that', 'not', 'only', 'will', \"shan't\", 'shouldn', 'me'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDiL9Y-RwdVX",
        "outputId": "416f44d1-19de-4900-82c5-85096437f566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusClean = []\n",
        "for doc in corpus:\n",
        "  arr = []\n",
        "  for word in doc:\n",
        "    if word not in stop_words:\n",
        "      arr.append(word)\n",
        "  corpusClean.append(arr)\n",
        "print(corpusClean)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['bitty', 'bought', 'bit', 'butter'], ['bit', 'butter', 'bit', 'bitter'], ['bought', 'better', 'butter', 'make', 'bitter', 'butter', 'better']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdhm5JTrwdQL"
      },
      "source": [
        "maxLen = -1\n",
        "for doc in corpusClean:\n",
        "  val = len(doc)\n",
        "  if maxLen < val:\n",
        "    maxLen = val  "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS4xtKYrxyT4",
        "outputId": "0df4619e-12ec-409b-ad05-5ce4a0fe35f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(maxLen)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUyvvvN0xy1l",
        "outputId": "4e98a4ac-c5ac-46c5-cd82-543dac605baa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusClean"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['bitty', 'bought', 'bit', 'butter'],\n",
              " ['bit', 'butter', 'bit', 'bitter'],\n",
              " ['bought', 'better', 'butter', 'make', 'bitter', 'butter', 'better']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkJrQoC5uZo9"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9TBV8lPuck2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU291KYRukzC"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYQUv9Tau8mY",
        "outputId": "ba4aead2-0733-4e33-f2d9-e612a449037d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusOneHot"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 42, 21, 24, 17, 42],\n",
              " [38, 41, 24, 17, 42, 26, 21, 24, 40],\n",
              " [32, 23, 42, 47, 16, 42, 5, 42, 41, 40, 42, 16]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8-f4aJiurrH"
      },
      "source": [
        "maxVocab = 50\n",
        "corpusClean = [' '.join(x) for x in corpusClean] \n",
        "corpusOneHot = [one_hot(x,maxVocab) for x in corpusClean]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB6jwCGry9TY",
        "outputId": "8aac493f-0761-42ab-fe8a-b443321b9f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusClean"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bitty bought bit butter',\n",
              " 'bit butter bit bitter',\n",
              " 'bought better butter make bitter butter better']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUhhjJE8y7GP",
        "outputId": "ca2794d2-558f-475b-e089-779ef1b6a36c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusOneHot"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 42, 24, 42], [24, 42, 24, 40], [42, 16, 42, 42, 40, 42, 16]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40q_Lo9Nu95r"
      },
      "source": [
        "corpusSequence = pad_sequences(corpusOneHot,maxlen=7,padding='post')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC6ZHKPayDsD",
        "outputId": "bc4f935f-f8ce-4fa0-d4d8-998b748bf4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpusSequence"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3, 42, 24, 42,  0,  0,  0],\n",
              "       [24, 42, 24, 40,  0,  0,  0],\n",
              "       [42, 16, 42, 42, 40, 42, 16]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7l0pEZczYL0"
      },
      "source": [
        "word_input = layers.Input(shape=(7,),dtype='float64')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwls9bWj2TX3",
        "outputId": "92d35312-cb0b-4a72-a63a-9044ad37e488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_input"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_2:0' shape=(None, 7) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IJYOstN2aVW"
      },
      "source": [
        "x = layers.Embedding(50,5)(word_input)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EBWmqtM28Uv",
        "outputId": "00f68169-df80-4409-a625-9536299362ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_1/embedding_lookup/Identity_1:0' shape=(None, 7, 5) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPA64oTZOovV"
      },
      "source": [
        "#**Sentiment Analysis - GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRLN3cB29Dd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twPEBzV5CTtu"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "325SYCGICadM",
        "outputId": "e76a5954-e646-4b50-90ba-3096eaf9761a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fwd3D1cCfT6"
      },
      "source": [
        "train_tweets = df_train['tweet']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBz8usurCkGP",
        "outputId": "4ba8a554-ed32-4ddc-c64e-3a113f6d7fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_tweets[1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCtwVNTNC5yR"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x480SotaFPLl",
        "outputId": "831b68eb-cec9-4d41-f65a-cf07f1eb891d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEd20joRFZPs",
        "outputId": "19878c28-794b-4187-8b4c-c42f082c7df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYDgJB_GFFeZ",
        "outputId": "cfe0739d-f4c3-4048-c0dc-b365031c7919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'too', 'own', 'll', \"shan't\", 'y', 'have', \"should've\", 'off', 'hers', 'with', 'on', 'but', 'been', 'her', 'over', 'these', 'ain', 'them', 'haven', 'me', 'against', 'yourselves', 'again', 'out', 'doing', 'during', 'herself', 'do', 'will', 'such', 'why', 'than', 'by', 'did', 'as', 'can', 'into', \"wasn't\", \"you'll\", 'myself', 'my', 'in', 'd', 'which', 'through', \"weren't\", 'further', 'itself', 'we', 'ours', 'that', 'because', 'wouldn', 'what', 'm', 'were', \"didn't\", \"isn't\", 'yours', 'who', 'how', 'himself', 'doesn', 'between', 'or', 'being', 'you', 'themselves', 'and', 'their', 'if', \"don't\", 'a', 'very', 'until', 'nor', 'theirs', 'when', 'all', 'our', 'only', 'so', 'those', 'below', 'she', \"doesn't\", \"it's\", 'yourself', 'while', 'after', 'is', \"that'll\", \"shouldn't\", 'some', 'are', 'any', 'i', 'at', 'for', 'isn', \"you'd\", 've', 'to', \"needn't\", 'don', 'mightn', 'more', 'should', 'ourselves', 'has', \"hadn't\", \"aren't\", 'then', 'o', 'its', 'there', \"you're\", 'having', 'where', 'had', 'ma', 'this', 'each', 'your', 'down', 'no', 'now', 'under', \"wouldn't\", 'same', \"won't\", 'shouldn', 'be', 'couldn', 'they', 'the', 'weren', 'up', 'about', 'am', 'an', 'both', 'aren', 'his', 'does', 'just', 'won', 'him', 'of', 'it', \"haven't\", 'whom', 'other', 'once', 'didn', \"couldn't\", 'shan', 'wasn', \"mustn't\", 'not', \"hasn't\", \"mightn't\", 'few', 'mustn', 'was', 'before', 'he', \"you've\", 't', 's', 'most', 'hasn', 'hadn', 'here', 're', 'from', 'needn', \"she's\", 'above'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_F-yLxpCpKa"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = re.sub(r'@\\w+',' ',text)\n",
        "  text = re.sub(r'[^a-zA-Z]',' ',text)\n",
        "  text = re.sub(r\"what's\", \"what is \", text)\n",
        "  text = re.sub(r\"\\'s\", \" \", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "  text = re.sub(r\"can't\", \"cannot \", text)\n",
        "  text = re.sub(r\"n't\", \" not \", text)\n",
        "  text = re.sub(r\"i'm\", \"i am \", text)\n",
        "  text = re.sub(r\"\\'re\", \" are \", text)\n",
        "  text = re.sub(r\"\\'d\", \" would \", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will \", text) \n",
        "  text = re.sub(r'ur',' your ', text) \n",
        "  text = text.lower()\n",
        "  text = word_tokenize(text)\n",
        "  \n",
        "  text = [word for word in text if not word in stop_words if len(word) > 2]\n",
        "\n",
        "  return text\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqIZsjV7EdNg"
      },
      "source": [
        "df_train['clean tweets'] = df_train['tweet'].apply(clean_text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUYIWBQPEubO",
        "outputId": "364561aa-2173-4d64-f9d4-6c44a935c808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                       clean tweets\n",
              "0   1  ...  [father, dysfunctional, selfish, drags, kids, ...\n",
              "1   2  ...  [thanks, lyft, credit, use, cause, offer, whee...\n",
              "2   3  ...                                  [bihday, majesty]\n",
              "3   4  ...                          [model, love, take, time]\n",
              "4   5  ...                  [factsguide, society, motivation]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gTzFYGKEwGi"
      },
      "source": [
        "a = df_train['tweet'][1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8pVRKPpF-EW",
        "outputId": "4467fe80-ff60-45bd-a8e8-589b7ba6c31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(clean_text(a))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thanks', 'lyft', 'credit', 'use', 'cause', 'offer', 'wheelchair', 'vans', 'pdx', 'disapointed', 'getthanked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLb8bFTTGEO7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TripSPnQHKQp"
      },
      "source": [
        "clean_tweets = df_train['clean tweets']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbjZOU41HeIb"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsMR5_yrH2qi",
        "outputId": "09977c47-df75-4a9b-bb06-09fe612a739c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clean_tweets = [' '.join(x) for x in clean_tweets]\n",
        "print(clean_tweets[:10])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['father dysfunctional selfish drags kids dysfunction run', 'thanks lyft credit use cause offer wheelchair vans pdx disapointed getthanked', 'bihday majesty', 'model love take time', 'factsguide society motivation', 'huge fan fare big talking leave chaos pay disputes get allshowandnogo', 'camping tomorrow danny', 'next school year year exams think school exams hate imagine actorslife revolutionschool girl', 'love land allin cavs champions cleveland clevelandcavaliers', 'welcome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mr4tC_RHuW1",
        "outputId": "812f1e2f-1360-4555-fe9f-093b387dcc20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "maxVocab = 10000\n",
        "clean_tweets_onehot = [one_hot(x,maxVocab) for x in clean_tweets]\n",
        "clean_tweets_onehot[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7356, 4441, 9900, 8750, 2795, 7191, 425],\n",
              " [17, 7444, 3746, 4371, 9982, 1442, 8417, 4624, 529, 7226, 26],\n",
              " [631, 7151],\n",
              " [4899, 657, 1386, 4771],\n",
              " [4324, 4753, 6367]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOKYbqZLIwCL",
        "outputId": "47048ec7-909b-4ddc-ec41-8998cdf3a302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "maxLen = -1\n",
        "for doc in clean_tweets_onehot:\n",
        "  if len(doc) > maxLen:\n",
        "    maxLen = len(doc)\n",
        "print(maxLen)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ga2jLXKIPpA",
        "outputId": "fc3dd547-0071-4a25-a9fa-fdd391b6ed15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "clean_tweets_pad = pad_sequences(clean_tweets_onehot,maxLen,padding='post')\n",
        "clean_tweets_pad[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7356, 4441, 9900, 8750, 2795, 7191,  425,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [  17, 7444, 3746, 4371, 9982, 1442, 8417, 4624,  529, 7226,   26,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 631, 7151,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4899,  657, 1386, 4771,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4324, 4753, 6367,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2jzBZ98JGlh"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYYbdAwJZRh"
      },
      "source": [
        "input = layers.Input(shape=(maxLen,), dtype='float64')\n",
        "word_embedding = layers.Embedding(maxVocab,128,input_length=maxLen)(input)\n",
        "x = layers.GRU(32,return_sequences=True,)(word_embedding)\n",
        "x = layers.GRU(64)(x)\n",
        "output = layers.Dense(1,activation='sigmoid')(x)\n",
        "model = Model(input,output)\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQOYMVN2NL9c",
        "outputId": "b8338981-3d75-4d77-ea02-f37eb9cdf3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_train = df_train['label'].values\n",
        "Y_train[:10]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjAvdg1mN0fv",
        "outputId": "2b15da32-7053-4ce7-8073-e381b46f121b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "H = model.fit(clean_tweets_pad,Y_train,batch_size=32,epochs=5,validation_split=0.2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "541/541 [==============================] - 9s 17ms/step - loss: 0.0694 - accuracy: 0.9778 - val_loss: 0.0736 - val_accuracy: 0.9750\n",
            "Epoch 2/5\n",
            "541/541 [==============================] - 9s 16ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.0916 - val_accuracy: 0.9734\n",
            "Epoch 3/5\n",
            "541/541 [==============================] - 9s 16ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.1104 - val_accuracy: 0.9697\n",
            "Epoch 4/5\n",
            "541/541 [==============================] - 9s 16ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1539 - val_accuracy: 0.9676\n",
            "Epoch 5/5\n",
            "541/541 [==============================] - 9s 16ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1570 - val_accuracy: 0.9664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9b7KDpmOf80"
      },
      "source": [
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxNU8oLERjjh",
        "outputId": "e717e776-5e1c-4a68-e5cc-004d5fe4ae35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErN4FOAiRk9h",
        "outputId": "ebd99dd6-541e-4f24-f9fc-abb9910cd028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_test['clean tweets'] = df_test['tweet'].apply(clean_text)\n",
        "df_test.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>[white, supremacists, want, everyone, see, new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[sed, child, book, reservations, already, yes,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>[bihday, amazing, hilarious, nephew, eli, ahmi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                       clean tweets\n",
              "0  31963  ...  [studiolife, aislife, requires, passion, dedic...\n",
              "1  31964  ...  [white, supremacists, want, everyone, see, new...\n",
              "2  31965  ...  [safe, ways, heal, acne, altwaystoheal, health...\n",
              "3  31966  ...  [sed, child, book, reservations, already, yes,...\n",
              "4  31967  ...  [bihday, amazing, hilarious, nephew, eli, ahmi...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnsaonKORu9X"
      },
      "source": [
        "clean_tweets_test = df_test['clean tweets']\n",
        "clean_tweets_test = [' '.join(x) for x in clean_tweets_test]\n",
        "clean_tweets_test_onehot = [one_hot(x,maxVocab) for x in clean_tweets_test]\n",
        "clean_tweets_test_pad = pad_sequences(clean_tweets_test_onehot,maxLen,padding='post')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTxZQ7blSREr",
        "outputId": "e87b5d49-e0c5-4be1-fe40-240afda647c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clean_tweets_test_pad[:5]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8676, 4833, 4562, 8724, 9542, 2170, 4749, 9608,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [1698, 1281, 2661, 3127, 8548, 8199, 2488, 5624,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [1589, 8916, 9023, 9174, 1779, 3872, 2235,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [8801, 9532, 1299, 7643, 3329, 8137, 1176, 5883, 9518,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 631, 8505, 8320, 1844, 7490, 1308,  659, 1782, 9797, 7373,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbhU5Xu9SX36"
      },
      "source": [
        "Y_pred = model.predict(clean_tweets_test_pad,batch_size=32)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ZEpRmbSfEX"
      },
      "source": [
        "Y_pred_f = list(map(lambda x: 1 if x > 0.5 else 0, Y_pred))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTpsCsYESiRk",
        "outputId": "42a75495-af99-46af-8a51-d1e57aa29db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_pred_f[:300]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUbyph23TErN"
      },
      "source": [
        "Y_train = Y_train.astype('float')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoV0gmkoTj8n",
        "outputId": "23df2e93-cc07-4dd8-a51b-ee9bab6f87c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_train[:20]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjPDTMITlWG",
        "outputId": "28e60a70-4186-4661-c07b-20ac6dc33fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(clean_tweets_pad,Y_train)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "676/676 [==============================] - 2s 3ms/step - loss: 0.0338 - accuracy: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03379938378930092, 0.9926395416259766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRD4Ln4bYbs3",
        "outputId": "2d2de0a2-f8e3-4058-b3dc-1c51c1a7c9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_test['label'] = Y_pred_f\n",
        "df_test.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean tweets</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>[white, supremacists, want, everyone, see, new...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[sed, child, book, reservations, already, yes,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>[bihday, amazing, hilarious, nephew, eli, ahmi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... label\n",
              "0  31963  ...     0\n",
              "1  31964  ...     1\n",
              "2  31965  ...     0\n",
              "3  31966  ...     0\n",
              "4  31967  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anM_gMYyYzBL",
        "outputId": "1f150a4b-6d2b-4a3f-ef5b-5380c8897e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_test.drop(['tweet','clean tweets'],axis=1,inplace=True)\n",
        "df_test.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  label\n",
              "0  31963      0\n",
              "1  31964      1\n",
              "2  31965      0\n",
              "3  31966      0\n",
              "4  31967      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHDTvzl7Y9lp"
      },
      "source": [
        "pd.DataFrame(df_test).to_csv('submissionGRU.csv',columns=['id','label'],index=None)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vLRzJfZIQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}